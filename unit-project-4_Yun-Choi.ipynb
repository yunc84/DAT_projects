{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-NYC-45 | Unit Project 4: Notebook with Executive Summary\n",
    "\n",
    "In this project, you will summarize and present your analysis from Unit Projects 1-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 1.  Introduction\n",
    "> Write a problem statement for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Determine which applicants will be admitted to UCLA, using application data (GRE score, GPA and school prestige) from UCLA's Logit Regression in R tutorial for the applicable application year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 2.  Dataset\n",
    "> Write up a description of your data and any cleaning that was completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "- Data Dictionary\n",
    "\n",
    "Variable | Description and Range | Type of Variable\n",
    "---|---|---\n",
    "admit | 0 = Not admitted, 1 = Admitted | Categorical\n",
    "gre | GRE score: [220, 800] | Continuous\n",
    "gpa | GPA score: [2.26, 4.00] | Continuous\n",
    "prestige | Prestige of applicant's alma mater: 1 = highest tier, 4 = lowest tier | Categorical\n",
    "\n",
    "- Data Cleaning: Dropped records with missing data. Out of 400 records, 3 records were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dataset/ucla-admissions.csv')\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> ## Question 3.  Demo\n",
    "> Provide a table that explains the data by admission status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "- Average of GRE and GPA scores by admission status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>573.579336</td>\n",
       "      <td>3.347159</td>\n",
       "      <td>2.645756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>618.571429</td>\n",
       "      <td>3.489206</td>\n",
       "      <td>2.150794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              gre       gpa  prestige\n",
       "admit                                \n",
       "0      573.579336  3.347159  2.645756\n",
       "1      618.571429  3.489206  2.150794"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('admit').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>prestige</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "prestige  1.0  2.0  3.0  4.0\n",
       "admit                       \n",
       "0          28   95   93   55\n",
       "1          33   53   28   12"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of applicants by prestige and admission status:\n",
    "pd.crosstab(df['admit'],df['prestige'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 4. Methods\n",
    "> Write up the methods used in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "- Logistic regression was performed on the admissions data against admittance (outcome varaible) to graduate school. \n",
    "- Input variables included GRE and GPA scores, and one-hot encoding using binary variables for the prestige variable.\n",
    "- For one-hot encoding, three dummy variables were created for `prestige` = 2, 3 and 4, so that the highest prestige undergraduate schools is the reference point.\n",
    "- Trained `sklearn`'s `LogisticRegression` model with `C=100`, using the entire dataset of 397 records (with the exception of dropped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prestige_dummy = pd.get_dummies(df['prestige'])\n",
    "df[['prestige_2','prestige_3','prestige_4']]=prestige_dummy[[2, 3, 4]]\n",
    "df.drop('prestige', axis=1, inplace=True)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(C = 10 ** 2)\n",
    "X = df.drop('admit', axis=1)\n",
    "y = df['admit']\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 5. Results\n",
    "> Write up your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "\n",
    "- Applying the exponential funciton, `np.exp()`, to the coefficients of logistic regression gives the estimated odds ratios for each feature.\n",
    "- The probability of admission, given the student's GRE and GPA scores and prestige of undergraudate school, can be calculated with the above coefficients (or by using the `predict_proba(X)` function.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 6. Visuals\n",
    "> Provide a table or visualization of these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "- Odds Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige_2</th>\n",
       "      <th>prestige_3</th>\n",
       "      <th>prestige_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>odds_ratio</th>\n",
       "      <td>1.002161</td>\n",
       "      <td>1.960413</td>\n",
       "      <td>0.533219</td>\n",
       "      <td>0.285867</td>\n",
       "      <td>0.208297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 gre       gpa  prestige_2  prestige_3  prestige_4\n",
       "odds_ratio  1.002161  1.960413    0.533219    0.285867    0.208297"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds_ratios = pd.DataFrame(data=np.exp(logreg.coef_), index=['odds_ratio'], columns=df.columns[1:])\n",
    "odds_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predicted probabilities of admission for student with a GRE of 800 and a GPA of 4 (by prestige):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tier</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.711854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.568463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.413911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.339755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      probability\n",
       "tier             \n",
       "1        0.711854\n",
       "2        0.568463\n",
       "3        0.413911\n",
       "4        0.339755"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = logreg.predict_proba([[800, 4, 0, 0, 0], [800, 4, 1, 0, 0], [800, 4, 0, 1, 0], [800, 4, 0, 0, 1]])\n",
    "probability = pd.DataFrame(data=prob[:,1], index=[1, 2, 3, 4], columns=['probability'])\n",
    "probability.index.name = 'tier'\n",
    "probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 7.  Discussion\n",
    "> Write up your discussion and future steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.317380352645 0.682619647355\n"
     ]
    }
   ],
   "source": [
    "p = df['admit'].mean()\n",
    "print p, 1-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70528967254408059"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 32% of 397 applicants (entire dataset minus dropped) were admitted and 68% of the applicants were not admitted.\n",
    "- In comparison, the logistic regression model correctly predicted only 71% of the applicants' admission status. (71% accuracy on the training set.)\n",
    "- This is poor performance because the logistic regression model marginally outperformed a simple model of predicting everyone will not be admitted. Furthermore, the logistic regression did not perform any cross validation or have a separate test set for final evaluation.\n",
    "- Next steps would be trying to fit different learning models such as random forests and performing cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98236775818639799"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 15)\n",
    "model.fit(X, y)\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.654789810908\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print cross_val_score(model, X, y, scoring='accuracy', cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prediction accuracy on the training set is high (98%).\n",
    "- However, with cross validation the prediction score drops below the lower bound of 68% (not admitted percentage).\n",
    "- The high prediction accuracy on the entire dataset was due to overfitting.\n",
    "- Dataset of 397 records is too small to perform robust fitting and testing with cross validation. Need more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
